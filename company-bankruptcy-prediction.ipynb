{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":42,"outputs":[{"output_type":"stream","text":"/kaggle/input/company-bankruptcy-prediction/data.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/company-bankruptcy-prediction/data.csv')\ndf","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"      Bankrupt?   ROA(C) before interest and depreciation before interest  \\\n0             1                                           0.370594          \n1             1                                           0.464291          \n2             1                                           0.426071          \n3             1                                           0.399844          \n4             1                                           0.465022          \n...         ...                                                ...          \n6814          0                                           0.493687          \n6815          0                                           0.475162          \n6816          0                                           0.472725          \n6817          0                                           0.506264          \n6818          0                                           0.493053          \n\n       ROA(A) before interest and % after tax  \\\n0                                    0.424389   \n1                                    0.538214   \n2                                    0.499019   \n3                                    0.451265   \n4                                    0.538432   \n...                                       ...   \n6814                                 0.539468   \n6815                                 0.538269   \n6816                                 0.533744   \n6817                                 0.559911   \n6818                                 0.570105   \n\n       ROA(B) before interest and depreciation after tax  \\\n0                                              0.405750    \n1                                              0.516730    \n2                                              0.472295    \n3                                              0.457733    \n4                                              0.522298    \n...                                                 ...    \n6814                                           0.543230    \n6815                                           0.524172    \n6816                                           0.520638    \n6817                                           0.554045    \n6818                                           0.549548    \n\n       operating gross margin   realized sales gross margin  \\\n0                    0.601457                      0.601457   \n1                    0.610235                      0.610235   \n2                    0.601450                      0.601364   \n3                    0.583541                      0.583541   \n4                    0.598783                      0.598783   \n...                       ...                           ...   \n6814                 0.604455                      0.604462   \n6815                 0.598308                      0.598308   \n6816                 0.610444                      0.610213   \n6817                 0.607850                      0.607850   \n6818                 0.627409                      0.627409   \n\n       operating profit rate   tax Pre-net interest rate  \\\n0                   0.998969                    0.796887   \n1                   0.998946                    0.797380   \n2                   0.998857                    0.796403   \n3                   0.998700                    0.796967   \n4                   0.998973                    0.797366   \n...                      ...                         ...   \n6814                0.998992                    0.797409   \n6815                0.998992                    0.797414   \n6816                0.998984                    0.797401   \n6817                0.999074                    0.797500   \n6818                0.998080                    0.801987   \n\n       after-tax net interest rate  \\\n0                         0.808809   \n1                         0.809301   \n2                         0.808388   \n3                         0.808966   \n4                         0.809304   \n...                            ...   \n6814                      0.809331   \n6815                      0.809327   \n6816                      0.809317   \n6817                      0.809399   \n6818                      0.813800   \n\n       non-industry income and expenditure/revenue  ...  \\\n0                                         0.302646  ...   \n1                                         0.303556  ...   \n2                                         0.302035  ...   \n3                                         0.303350  ...   \n4                                         0.303475  ...   \n...                                            ...  ...   \n6814                                      0.303510  ...   \n6815                                      0.303520  ...   \n6816                                      0.303512  ...   \n6817                                      0.303498  ...   \n6818                                      0.313415  ...   \n\n      net income to total assets  total assets to GNP price  \\\n0                       0.716845                   0.009219   \n1                       0.795297                   0.008323   \n2                       0.774670                   0.040003   \n3                       0.739555                   0.003252   \n4                       0.795016                   0.003878   \n...                          ...                        ...   \n6814                    0.799927                   0.000466   \n6815                    0.799748                   0.001959   \n6816                    0.797778                   0.002840   \n6817                    0.811808                   0.002837   \n6818                    0.815956                   0.000707   \n\n      No-credit interval  Gross profit to Sales  \\\n0               0.622879               0.601453   \n1               0.623652               0.610237   \n2               0.623841               0.601449   \n3               0.622929               0.583538   \n4               0.623521               0.598782   \n...                  ...                    ...   \n6814            0.623620               0.604455   \n6815            0.623931               0.598306   \n6816            0.624156               0.610441   \n6817            0.623957               0.607846   \n6818            0.626680               0.627408   \n\n      Net income to stockholder's Equity  liability to equity  \\\n0                               0.827890             0.290202   \n1                               0.839969             0.283846   \n2                               0.836774             0.290189   \n3                               0.834697             0.281721   \n4                               0.839973             0.278514   \n...                                  ...                  ...   \n6814                            0.840359             0.279606   \n6815                            0.840306             0.278132   \n6816                            0.840138             0.275789   \n6817                            0.841084             0.277547   \n6818                            0.841019             0.275114   \n\n      Degree of financial leverage (DFL)  \\\n0                               0.026601   \n1                               0.264577   \n2                               0.026555   \n3                               0.026697   \n4                               0.024752   \n...                                  ...   \n6814                            0.027064   \n6815                            0.027009   \n6816                            0.026791   \n6817                            0.026822   \n6818                            0.026793   \n\n      Interest coverage ratio( Interest expense to EBIT )  \\\n0                                              0.564050     \n1                                              0.570175     \n2                                              0.563706     \n3                                              0.564663     \n4                                              0.575617     \n...                                                 ...     \n6814                                           0.566193     \n6815                                           0.566018     \n6816                                           0.565158     \n6817                                           0.565302     \n6818                                           0.565167     \n\n      one if net income was negative for the last two year zero otherwise  \\\n0                                                     1                     \n1                                                     1                     \n2                                                     1                     \n3                                                     1                     \n4                                                     1                     \n...                                                 ...                     \n6814                                                  1                     \n6815                                                  1                     \n6816                                                  1                     \n6817                                                  1                     \n6818                                                  1                     \n\n      equity to liability  \n0                0.016469  \n1                0.020794  \n2                0.016474  \n3                0.023982  \n4                0.035490  \n...                   ...  \n6814             0.029890  \n6815             0.038284  \n6816             0.097649  \n6817             0.044009  \n6818             0.233902  \n\n[6819 rows x 96 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bankrupt?</th>\n      <th>ROA(C) before interest and depreciation before interest</th>\n      <th>ROA(A) before interest and % after tax</th>\n      <th>ROA(B) before interest and depreciation after tax</th>\n      <th>operating gross margin</th>\n      <th>realized sales gross margin</th>\n      <th>operating profit rate</th>\n      <th>tax Pre-net interest rate</th>\n      <th>after-tax net interest rate</th>\n      <th>non-industry income and expenditure/revenue</th>\n      <th>...</th>\n      <th>net income to total assets</th>\n      <th>total assets to GNP price</th>\n      <th>No-credit interval</th>\n      <th>Gross profit to Sales</th>\n      <th>Net income to stockholder's Equity</th>\n      <th>liability to equity</th>\n      <th>Degree of financial leverage (DFL)</th>\n      <th>Interest coverage ratio( Interest expense to EBIT )</th>\n      <th>one if net income was negative for the last two year zero otherwise</th>\n      <th>equity to liability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.370594</td>\n      <td>0.424389</td>\n      <td>0.405750</td>\n      <td>0.601457</td>\n      <td>0.601457</td>\n      <td>0.998969</td>\n      <td>0.796887</td>\n      <td>0.808809</td>\n      <td>0.302646</td>\n      <td>...</td>\n      <td>0.716845</td>\n      <td>0.009219</td>\n      <td>0.622879</td>\n      <td>0.601453</td>\n      <td>0.827890</td>\n      <td>0.290202</td>\n      <td>0.026601</td>\n      <td>0.564050</td>\n      <td>1</td>\n      <td>0.016469</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.464291</td>\n      <td>0.538214</td>\n      <td>0.516730</td>\n      <td>0.610235</td>\n      <td>0.610235</td>\n      <td>0.998946</td>\n      <td>0.797380</td>\n      <td>0.809301</td>\n      <td>0.303556</td>\n      <td>...</td>\n      <td>0.795297</td>\n      <td>0.008323</td>\n      <td>0.623652</td>\n      <td>0.610237</td>\n      <td>0.839969</td>\n      <td>0.283846</td>\n      <td>0.264577</td>\n      <td>0.570175</td>\n      <td>1</td>\n      <td>0.020794</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0.426071</td>\n      <td>0.499019</td>\n      <td>0.472295</td>\n      <td>0.601450</td>\n      <td>0.601364</td>\n      <td>0.998857</td>\n      <td>0.796403</td>\n      <td>0.808388</td>\n      <td>0.302035</td>\n      <td>...</td>\n      <td>0.774670</td>\n      <td>0.040003</td>\n      <td>0.623841</td>\n      <td>0.601449</td>\n      <td>0.836774</td>\n      <td>0.290189</td>\n      <td>0.026555</td>\n      <td>0.563706</td>\n      <td>1</td>\n      <td>0.016474</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0.399844</td>\n      <td>0.451265</td>\n      <td>0.457733</td>\n      <td>0.583541</td>\n      <td>0.583541</td>\n      <td>0.998700</td>\n      <td>0.796967</td>\n      <td>0.808966</td>\n      <td>0.303350</td>\n      <td>...</td>\n      <td>0.739555</td>\n      <td>0.003252</td>\n      <td>0.622929</td>\n      <td>0.583538</td>\n      <td>0.834697</td>\n      <td>0.281721</td>\n      <td>0.026697</td>\n      <td>0.564663</td>\n      <td>1</td>\n      <td>0.023982</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0.465022</td>\n      <td>0.538432</td>\n      <td>0.522298</td>\n      <td>0.598783</td>\n      <td>0.598783</td>\n      <td>0.998973</td>\n      <td>0.797366</td>\n      <td>0.809304</td>\n      <td>0.303475</td>\n      <td>...</td>\n      <td>0.795016</td>\n      <td>0.003878</td>\n      <td>0.623521</td>\n      <td>0.598782</td>\n      <td>0.839973</td>\n      <td>0.278514</td>\n      <td>0.024752</td>\n      <td>0.575617</td>\n      <td>1</td>\n      <td>0.035490</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6814</th>\n      <td>0</td>\n      <td>0.493687</td>\n      <td>0.539468</td>\n      <td>0.543230</td>\n      <td>0.604455</td>\n      <td>0.604462</td>\n      <td>0.998992</td>\n      <td>0.797409</td>\n      <td>0.809331</td>\n      <td>0.303510</td>\n      <td>...</td>\n      <td>0.799927</td>\n      <td>0.000466</td>\n      <td>0.623620</td>\n      <td>0.604455</td>\n      <td>0.840359</td>\n      <td>0.279606</td>\n      <td>0.027064</td>\n      <td>0.566193</td>\n      <td>1</td>\n      <td>0.029890</td>\n    </tr>\n    <tr>\n      <th>6815</th>\n      <td>0</td>\n      <td>0.475162</td>\n      <td>0.538269</td>\n      <td>0.524172</td>\n      <td>0.598308</td>\n      <td>0.598308</td>\n      <td>0.998992</td>\n      <td>0.797414</td>\n      <td>0.809327</td>\n      <td>0.303520</td>\n      <td>...</td>\n      <td>0.799748</td>\n      <td>0.001959</td>\n      <td>0.623931</td>\n      <td>0.598306</td>\n      <td>0.840306</td>\n      <td>0.278132</td>\n      <td>0.027009</td>\n      <td>0.566018</td>\n      <td>1</td>\n      <td>0.038284</td>\n    </tr>\n    <tr>\n      <th>6816</th>\n      <td>0</td>\n      <td>0.472725</td>\n      <td>0.533744</td>\n      <td>0.520638</td>\n      <td>0.610444</td>\n      <td>0.610213</td>\n      <td>0.998984</td>\n      <td>0.797401</td>\n      <td>0.809317</td>\n      <td>0.303512</td>\n      <td>...</td>\n      <td>0.797778</td>\n      <td>0.002840</td>\n      <td>0.624156</td>\n      <td>0.610441</td>\n      <td>0.840138</td>\n      <td>0.275789</td>\n      <td>0.026791</td>\n      <td>0.565158</td>\n      <td>1</td>\n      <td>0.097649</td>\n    </tr>\n    <tr>\n      <th>6817</th>\n      <td>0</td>\n      <td>0.506264</td>\n      <td>0.559911</td>\n      <td>0.554045</td>\n      <td>0.607850</td>\n      <td>0.607850</td>\n      <td>0.999074</td>\n      <td>0.797500</td>\n      <td>0.809399</td>\n      <td>0.303498</td>\n      <td>...</td>\n      <td>0.811808</td>\n      <td>0.002837</td>\n      <td>0.623957</td>\n      <td>0.607846</td>\n      <td>0.841084</td>\n      <td>0.277547</td>\n      <td>0.026822</td>\n      <td>0.565302</td>\n      <td>1</td>\n      <td>0.044009</td>\n    </tr>\n    <tr>\n      <th>6818</th>\n      <td>0</td>\n      <td>0.493053</td>\n      <td>0.570105</td>\n      <td>0.549548</td>\n      <td>0.627409</td>\n      <td>0.627409</td>\n      <td>0.998080</td>\n      <td>0.801987</td>\n      <td>0.813800</td>\n      <td>0.313415</td>\n      <td>...</td>\n      <td>0.815956</td>\n      <td>0.000707</td>\n      <td>0.626680</td>\n      <td>0.627408</td>\n      <td>0.841019</td>\n      <td>0.275114</td>\n      <td>0.026793</td>\n      <td>0.565167</td>\n      <td>1</td>\n      <td>0.233902</td>\n    </tr>\n  </tbody>\n</table>\n<p>6819 rows Ã— 96 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"Bankrupt?                                                                int64\n ROA(C) before interest and depreciation before interest               float64\n ROA(A) before interest and % after tax                                float64\n ROA(B) before interest and depreciation after tax                     float64\n operating gross margin                                                float64\n                                                                        ...   \nliability to equity                                                    float64\nDegree of financial leverage (DFL)                                     float64\nInterest coverage ratio( Interest expense to EBIT )                    float64\none if net income was negative for the last two year zero otherwise      int64\nequity to liability                                                    float64\nLength: 96, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sum().isnull()","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"Bankrupt?                                                              False\n ROA(C) before interest and depreciation before interest               False\n ROA(A) before interest and % after tax                                False\n ROA(B) before interest and depreciation after tax                     False\n operating gross margin                                                False\n                                                                       ...  \nliability to equity                                                    False\nDegree of financial leverage (DFL)                                     False\nInterest coverage ratio( Interest expense to EBIT )                    False\none if net income was negative for the last two year zero otherwise    False\nequity to liability                                                    False\nLength: 96, dtype: bool"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Bankrupt?'].value_counts()","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"0    6599\n1     220\nName: Bankrupt?, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\ndef balancing_dataset(X, y):\n  smote = SMOTE(sampling_strategy='minority')\n  X_sm, y_sm = smote.fit_sample(X,y)\n  return X_sm, y_sm","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = balancing_dataset(df.drop('Bankrupt?', axis=1), df['Bankrupt?'])","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"0    6599\n1    6599\nName: Bankrupt?, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score, plot_roc_curve, accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom lightgbm import LGBMClassifier\n\nmodels = {\n  \"svc\": SVC(),\n  \"gradBoost\": GradientBoostingClassifier(),\n  \"AdaBoost\": AdaBoostClassifier(),\n  \"RandomForest\": RandomForestClassifier(),\n  \"XGB\": XGBClassifier(),\n  \"XGBRF\": XGBRFClassifier(),\n  \"LGBM\": LGBMClassifier(),\n  \"logReg\": LogisticRegression(),\n  \"NB_gauss\": GaussianNB(),\n  \"KNN\": KNeighborsClassifier(),\n}","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_validate\n\ndef cross_val_scoring(models, X, y, cv, scoring):\n  np.random.seed(42)\n  model_scoring = {}\n  for name, model in models.items():\n    pipe = Pipeline(steps=[\n                      ('imputer', SimpleImputer()),\n                      ('scaler', StandardScaler()),\n                      ('model', model),\n    ])\n    scores = cross_validate(pipe, X, y, scoring=scoring)\n    model_scoring[name] = scores\n  return model_scoring","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nkf = KFold(n_splits=5)\n\nscoring = {\n    'accuracy': 'accuracy',\n}","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_model_scores = cross_val_scoring(models, X, y, kf, scoring)","execution_count":53,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:48:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:48:13] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:48:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:48:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:48:34] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:48:47] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:48:53] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:48:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:49:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[00:49:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, score in cv_model_scores.items():\n  print(\"=== \"+name+\" (test)===\");\n  print(\"mean accuracy: {} (+/- {})\".format(score['test_accuracy'].mean(), score['test_accuracy'].std()))","execution_count":54,"outputs":[{"output_type":"stream","text":"=== svc (test)===\nmean accuracy: 0.9430249061283543 (+/- 0.028375914562011058)\n=== gradBoost (test)===\nmean accuracy: 0.946282568006706 (+/- 0.022603213301768853)\n=== AdaBoost (test)===\nmean accuracy: 0.9213553974760871 (+/- 0.029760001035833362)\n=== RandomForest (test)===\nmean accuracy: 0.9715125678918783 (+/- 0.013864710074520323)\n=== XGB (test)===\nmean accuracy: 0.9773469059675957 (+/- 0.01578368652388239)\n=== XGBRF (test)===\nmean accuracy: 0.936887107145728 (+/- 0.021792139845992424)\n=== LGBM (test)===\nmean accuracy: 0.9743925040476764 (+/- 0.019487235730270665)\n=== logReg (test)===\nmean accuracy: 0.8927158186640944 (+/- 0.041996792352749494)\n=== NB_gauss (test)===\nmean accuracy: 0.7167040717902786 (+/- 0.09744864416796131)\n=== KNN (test)===\nmean accuracy: 0.9263565170461723 (+/- 0.03409524891299726)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)","execution_count":56,"outputs":[{"output_type":"stream","text":"[00:49:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(X_test, y_test)","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"0.9875"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\ny_pred = model.predict(X_test)\nf1_score(y_test, y_pred)","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"0.9874476987447698"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model, X_test, y_test ,cmap='Blues')","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2c1b983f50>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}